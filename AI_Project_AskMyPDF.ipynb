{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMyou6uk4jCi7Odsy/d/rXd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Panos997/Borderless-Table-Location-in-Scanned-Legal-Documents-using-Object-Detection-Models/blob/main/AI_Project_AskMyPDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbJWu_oIPimv"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Install dependencies\n",
        "!apt-get -y install poppler-utils tesseract-ocr\n",
        "!pip install pytesseract pdf2image sentence-transformers transformers chromadb gradio\n",
        "\n",
        "# Cell 2: PDF QA Interface with Gradio\n",
        "import pytesseract\n",
        "from pdf2image import convert_from_path\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import chromadb\n",
        "from chromadb.config import Settings\n",
        "from transformers import pipeline\n",
        "import gradio as gr\n",
        "\n",
        "# Initialize models and database client\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "client = chromadb.Client(Settings(anonymized_telemetry=False))\n",
        "collection = None\n",
        "qa_pipeline = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "\n",
        "def process_pdf(file):\n",
        "    try:\n",
        "        global collection\n",
        "\n",
        "        # 1) If there’s an old collection, delete it\n",
        "        try:\n",
        "            client.delete_collection(\"pdf_agent\")\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "        # 2) Create a fresh one\n",
        "        collection = client.create_collection(\"pdf_agent\")\n",
        "\n",
        "        # 3) OCR each page\n",
        "        images = convert_from_path(file.name)\n",
        "        pages = [pytesseract.image_to_string(img) for img in images]\n",
        "\n",
        "        # 4) Chunk into overlapping 500‐char slices\n",
        "        chunks = []\n",
        "        for page in pages:\n",
        "            for i in range(0, len(page), 450):\n",
        "                chunks.append(page[i:i+500])\n",
        "\n",
        "        # 5) Embed & store\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            emb = model.encode(chunk).tolist()\n",
        "            collection.add(\n",
        "                documents=[chunk],\n",
        "                embeddings=[emb],\n",
        "                ids=[str(i)]\n",
        "            )\n",
        "\n",
        "        return f\"✅ Processed {len(pages)} pages into {len(chunks)} chunks.\"\n",
        "    except Exception:\n",
        "        import traceback\n",
        "        return \"⚠️ Error during processing:\\n\" + traceback.format_exc()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def answer_question(question, top_k):\n",
        "    if collection is None:\n",
        "        return \"Please upload and process a PDF first.\"\n",
        "    query_emb = model.encode(question).tolist()\n",
        "    results = collection.query(query_embeddings=[query_emb], n_results=top_k)\n",
        "    answers = []\n",
        "    for chunk in results['documents'][0]:\n",
        "        res = qa_pipeline(question=question, context=chunk)\n",
        "        answers.append(f\"{res['answer']} (confidence: {res['score']*100:.2f}%)\")\n",
        "    return \"\\n\\n\".join(answers)\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## PDF Question‑Answering Interface\")\n",
        "    pdf_input = gr.File(label=\"Upload PDF\", file_types=[\".pdf\"])\n",
        "    process_btn = gr.Button(\"Process PDF\")\n",
        "    status = gr.Textbox(label=\"Status\", interactive=False)\n",
        "    question = gr.Textbox(label=\"Question\")\n",
        "    top_k = gr.Slider(1, 10, value=3, step=1, label=\"Top K Chunks\")\n",
        "    ask_btn = gr.Button(\"Ask\")\n",
        "    answer = gr.Textbox(label=\"Answer\", interactive=False)\n",
        "\n",
        "    process_btn.click(fn=process_pdf, inputs=pdf_input, outputs=status)\n",
        "    ask_btn.click(fn=answer_question, inputs=[question, top_k], outputs=answer)\n",
        "\n",
        "demo.launch(share=True)"
      ]
    }
  ]
}